# 9. S3와 유사한 객체 저장소

## 9.2 개략적 설계안 제시 및 동의 구하기
##### 객체 불변성
- 객체 저장소와 다른 두가지 유형의 저장소 차이점: 보관되는 객체들은 변경이 불가능
- 삭제한 다음 새 버전 객체로 완전히 대체할 수 있어도 그 값을 변경할 수 없음

##### 키-값 저장소
- 해당 객체의 URI를 사용하여 데이터를 가져올 수 있음
- URI는 키이며, 데이터는 값에 해당 함
````
요청: 
GET /bucket1/object1.txt HTTP/1.1

응답:
HTTP/1.1 200 OK
Content-Length: 4567

[해당 객체의 데이터 4567 바이트]
````
##### 저장은 1회, 읽기는 여러 번
- 데이터 접근 패턴 측면에서 쓰기는 1회, 읽기는 여러번 발생
##### 소형 및 대형 객체 동시 지원
- 다양한 크기의 객체를 문제없이 저장 가능

##### 객체 저장소와 UNIX 파일 시스템의 설계 철학<br>
<img src="304.9.2" alt="drawing" width="300px"/><br>
- UNIX는 로컬에 파일 저장할 때, 파일의 이름과 데이터를 같은 곳에 저장되지 않음
  - 아이노드(inode)라고 불리는 자료 구조에 보관, 데이터는 디스크의 다른 위치에 저장
  - 파일을 읽을때 아이노드에 있는 파일 블록 포인트를 통해 데이터를 읽음
- 객체 저장소도 아이 노드에 대응되는 '메타데이터 저장소' 가 존재
- 메타데이터와 실제 데이터를 분리하면? 실제 데이터와는 독립적으로 메타데이터를 유연하게 변경 가능(구현 최적화)

##### 개략적 설계안
- 시스템 개략적인 설계안<br>
<img src="305.9.4" alt="drawing" width="300px"/><br>
  - 로드밸런서: RESTful API에 대한 요청을 API 서버들에 분산하는 역할 담당
  - API 서비스: IAM 서비스, 메타데이터 서비스, 저장 서비스에 대한 호출 조율 담당, 무상태 및 수평적 확장 가능
  - IAM 서비스: 인증, 권한 부여, 접근 제어등을 중앙에서 맡아 처리
  - 데이터 자장소: 실제 데이터를 보관하고 필요할 때마다 읽어가는 저장소, 데이터 관련 연상은 객체ID(UUID)를 통함
  - 메타데이터 저장소: 객체 메타데이터를 보관
- 메타데이터 저장소와 데이터 저장소는 논리적일 구분일 뿐, 구현 방법은 여러 가지 있을 수 있음
- 객체 업로드<br>
  <img src="307.9.5" alt="drawing" width="300px"/><br>
  - ① 클라이언트 bucket-to-share 버킷 생성을 위해 HTTP PUT 요청을 보냄
  - ② API 서비스는 IAM를 호출하여 write 권한 체크
  - ③ API 서비스는 버킷 정보를 등록하기 위해 메타 데이터 저장소 호출
  - ④ 버킷이 만들어지면 클라이언트는 script.txt 객체를 생성하기 위해 HTTP PUT 요청
  - ⑤ API 서비스는 신원 및 write 권한 체크
  - ⑥ 확인 결과 문제 없으면 HTTP PUT 요청에 담긴 객체 데이터를 저장소로 보냄, 객체 저장 후 반환 값으로 UUID 반환
  - ⑦ API 서비스는 메타데이터 저장소 호풀하여 새로운 항목 등록

  | object_name | object_id                            | bucket_id                             |
  |-------------|--------------------------------------|---------------------------------------|
  | script.txt  | 239D5866-0052-00F6-014E-C914E61ED42B | 82AA1B2E-F599-4590-B5E4-1F51AAE-5F7E4 |

````
요청: 
PUT /bucket-to-share/script.txt HTTP/1.1
Host: foo.s3example.org
Date: Sun, 12 Sept 2021 17:51:00 GMT
Authorization: [권한 문자열]
Content-Type: text/plain
Content-Length: 4567 
x-amz-meta-author: Alex
[객체 데이터 4567 바이트]
````
- 객체 다운로드<br>
  - 버켓은 디렉터리 같은 구조를 지원하지 않음, 버켓이름과 객체이름을 연결하면 논리적 계층 가능
  - 아래 처럼 요청 가능
````
요청: 
GET /bucket-to-share/script.txt HTTP/1.1
Host: foo.s3example.org
Date: Sun, 12 Sept 2021 18:30:01 GMT
Authorization: [권한 문자열]
````
  - 객체 다운로드 프로세스<br>
    <img src="309.9.6" alt="drawing" width="300px"/><br>
    - ① 클라이언트로 'GET /bucket-to-share/script.txt' 요청을 로드밸런서로 보냄, 로드밸런서는 API 서버로 전달
    - ② API 서비스는 IAM에게 Read권한 체크
    - ③ 권한 확인 후 API 서비스는 해당 객체의 UUID를 메타데이터 저장소에서 가져옴
    - ④ API 서비스는 해당 UUID를 사용해 데이터 저장소에서 객체 데이터를 가져옴
    - ⑤ API 서비스는 HTTP GET 요청에 대한 응답으로 해당 객체 데이터를 반환

## 9.3 상세 설계
##### 데이터 저장소
- 
##### 메타데이터 데이터 모델
- 스키마
  - 3가지 질의를 지원할 수 있어야 함
    - 객체 이름으로 객체 ID 찾기
    - 객체 이름에 기반하여 객체 삽입 또는 삭제
    - 같은 접두어를 갖는 버킷 내의 모든 객체 목록 확인
  - 이 조건을 만족하는 데이터베이스 스키마<br>
    <img src="326.9.21" alt="drawing" width="300px"/><br>
    (?) 왜 object 테이블 내 bucket_id가 아닌 name을 넣었을까?
- bucket 테이블의 규모 확장
  - 보통 한사용자가 만들 수 있는 버킷의 수는 제한적
    - 고객이 100만명이고, 고객마다 10개의 버킷을 갖고 있으며 한 레코드의 크기는 10KB라고 가정 -> 10GB(백만 x 10 x 10KB)의 저장공간 필요
  - 전체 테이블은 최신 데이터베이스 서버 한 대에 충분히 저장 가능할수도 있지만 모든 읽기 요청을 처리하기에는 CPU 용량이나 네트워크 대역폭 부족 -> 사본을 통해 해결
- object 테이블의 규모 확장
  - 객체 메타데이터를 보관 -> 데이터베이스 한대에 보관 불가능 -> 샤딩을 통해 테이블 규모 확장
  - 테이블 샤딩하는 한 가지 방법은 bucket_id를 기준으로 배치 -> 핫스팟 샤드 지원이 안되어 좋은 방안이 아님
  - object_id를 기준으로 샤딩 -> 부하를 균등하게 분산하지만 질의 1과 2를 효율적으로 지원 못함
  - 본 설계안에서는 bucket_name과 object_name을 결합하여 샤딩 활용 -> 연산이 객체 URI를 기준 -> 세 번째 질의는 다소 애매
##### 버킷 내의 객체 목록 확인
- 객체를 파일 시스템처럼 계층적 구조로 보관히자 않음 -> s3://<버킷 이름>/<객체 이름>의 수평적 접근
  - s3://my-bucket/abc/d/e/f/file.txt -> my-bucket은 버킷 이름, abc/d/e/f/file.txt는 객체 이름
- 사용자가 버킷 내 객체를 잘 정리할 수 있도록 하기 위해 S3s는 '접두어'라는 개념을 지원 -> 잘 활용하면 디렉터리와 비슷하게 데이터 정리 가능
- 어떤 접두어에 대응되는 객체 목록을 얻으려하면 오직 해당 접두어로 시작하는 이름의 객체만 반환
  - 'aws s3 ls s3://mybucket/abc/'로 하면 출력되지 않음 -> 'aws s3 ls s3://mybucket/abc/ --recursive'
- 단일 데이터베이스 서버
  - 특정 사용자가 가진 모든 버킷을 출력하려면 다음 질의 실행
  ````
  SELECT * FROM bucket WEHRE owner_id={id}  
  ````
  - 같은 접두어를 갖는, 버킷 내 모든 객체를 출력하려면 다음과 같은 질의 실행
  ````
  SELECT * FROM object WEHRE bucket_id="123" AND object_name LIKE 'abc/%'  
  ````
  - 위와 같은 방법으로 세번째 용례(같은 접두어를 갖는 버킷 내의 모든 객체 목록) 구현 가능
- 분산 데이터베이스
  - 메타데이터 테이블을 샤딩하면 어떤 샤드에 데이터가 있는지 모르므로 목록 출력 기능 구현 어려움
  - 해결안으로 검색 질의를 모든 샤드에 돌린 다음 결과 취합
    - 메타데이터 서비스는 모든 샤드에 다음 질의를 돌림
     ````
      SELECT * FROM object WEHRE bucket_id="123" AND object_name LIKE 'abc/%'  
     ````
    - 메타데이터 서비스는 각 샤드가 반환한 객체들을 취합하여 그 결과를 반환
  - 해당 방법에 페이지 나눔(patination)기능을 구현하기 복잡함
    - 객체가 여러 샤드에 나눠져 있으므로, 샤드마다 반환하는 객체 수는 제각각 -> 샤드마다 추적해야할 오프셋이 달라질 수 있음
    - 데이터가 많아지면 모든 샤드의 오프셋을 추적 -> 샤드 개수가 수백개면 오프셋도 수백개
  - 객체 저장소는 객체 목록 출력 명령의 성능보다 규모와 내구성 최적화가 더 중요
  - 버킷 ID로 샤딩하는 별도 테이블에 목록 데이터를 비정규화 하는 방법도 존재
##### 객체 버전
- 버킷 안에 한 객체의 여러 버전을 둘 수 있도록 하는 기능 -> 실수로 지우거나 덮어 쓴 객체를 쉽게 복구
- 객체 저장소는 해당 문서의 모든 이전 버전을 메타데이터 저장소에 유지하고, 이전 버전에 삭제 표시를 하지 않음
- 버전 유지 되는 객체의 업로드<br>
  <img src="332.9.22" alt="drawing" width="300px"/><br>
  - 클라이언트는 script.txt 객체를 업로드하기 위해 HTTP PUT 요청
  - API 서비스는 신원 및 권한 확인
  - 확인 후, API 서비스는 데이터를 데이터 저장소에 업로드 -> 저장 후 UUID 반환
  - API 서비스는 메타데이터 저장소를 호출하여 새 객체의 메타데이터 정보를 보관
  - 버전 기능 지원을 위해 메타데이터 저장소의 객체 테이블에는 object_version 열 존재 -> 버전 기능 활성화에만 사용
    - 기존 레코드를 덮어쓰는 대신, bucket_id와 object_name은 같지만 object_id, object_version은 새로운 값인 레코드를 추가
    - object_version은 TIMEUUID -> 가장 큰 값이 최신 버전
- 객체를 삭제할 때는 해당 객체의 모든 버전을 버킷 안에 그대로 둔 채 단순히 삭제 표식만 추가<br>
<img src="333.9.24" alt="drawing" width="300px"/><br>
  - 삭제된 버전을 조회하면 404 Object Not Found 오류 반환
##### 큰 파일의 업로드 성능 최적화
- 개략적으로 시스템 규모 추정 시, 20% 정도는 크기가 크다고 가정 -> 몇 GB 객체일 수 도 있음
- 직적 업로드도 가능하지만 큰 객체를 작게 쪼갠 다음에 독립적으로 올리는게 더 좋음
  - 업로드 중간에 네트워크 문제로 처음부터 업로드 문제 해소
- 모든 조각이 업로드되고 나면 객체 저장소는 조각을 모아 원본 객체를 복원 -> 멀티파트(multipart)업로드라고 부름
- 멀티파트 업로드 동작 방식<br>
  <img src="334.9.25" alt="drawing" width="300px"/><br>
  - ① 클라이언트가 멀티파트 업로드 시작을 위해 객체 저장소 호출
  - ② 데이터 저장소가 uploadID 반환 -> 업로드를 유일하게 식별한 ID
  - ③ 클라이언트는 파일을 작은 객체로 분할한 뒤에 업로드 시작, 조갠 조각을 ETag와 함께 데이터 저장소에 올림
  - ④ 조각 하나가 업로드 될 때마다 데이터 저장소는 ETag를 반환 -> ETag는 해당 조각에 대한 MD5 해시 체크섬(업로드 정상 유무 검사용)
  - ⑤ 모든 조각을 업로드하고 나면 클라이언트는 멀티파트 업로드 종료 요청, uploadID, 조각번호 목록, Etag 목록 포함
  - ⑥ 데이터 저장소는 조각 번호 목록을 사용해 원본 객체를 복원, 복원 성공 후 성공 메시지 반환
- 객체 조립이 끝난 뒤에는 조각이 더 쓸모가 없어진다는 문제점 -> 조각 삭제를 통해 저장 용량 확보 필요(쓰레기 수집 프로세스 필요)
##### 쓰레기 수집(garbage collection)
- 더이상 사용되지 않는 데이터에 할당된 저장 공간을 자동으로 회수하는 절차
- 다음과 같은 경우에 쓰레기 데이터가 생길 수 있음
  - 객체의 지연 삭제: 삭제했다고 표시는 하지만 실제 지우지 않음
  - 갈 곳 없는 데이터: 반쯤 업로드된 데이터, 또는 취소된 멀티파트 업로드 데이터
  - 훼손된 데이터: 체크섬 검사에 실패한 데이터
- 쓰레기 수집기는 객체를 데이터 저장소에서 바로 지우지 않음 -> 객체 정리 매커니즘을 주기적으로 실행하여 지움
  - 쓰레기 수집기는 사용되지 않는 사본에 할당된 저장 공간을 회수하는 역할
- 데이터를 다중화하는 경우에는 주 저장소와 함께 부 저장소 노드에서도 지워야함
- 쓰레기 수집기의 정리 매커니즘<br>
  <img src="336.9.26" alt="drawing" width="300px"/><br>
  - 쓰레기 수집기는 /data/b의 객체를 /data/d로 복사, 객체 2와 객체 5는 건너뜀(삭제된 객체임을 알리는 플래그가 참)
  - 모든 객체를 복사한 다음 쓰레기 수집기는 object_mapping 테이블을 갱신 -> 갱신 연산은 같은 트랜잭션 안에서 수행하는 것이 바람직함
- 정리 후 새파일 크기는 종전보다 작음 -> 작은 파일이 많이 만들어지는 것을 방지하기 위해 읽기 전용 파일이 많아 질때까지 기다림
- 추후 여러 일기 전용 파일에 기록된 객체를 하나의 파일로 모음

## 9.4 마무리
- 면접의 핵심은 객체 저장소를 설계하는 것
  - 객체 업로드
  - 객체 다운로드
  - 버킷 내 객체 목록 표시
  - 객체 버전